{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60af2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import shutil, sys    \n",
    "\n",
    "import glob\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "\n",
    "\n",
    "import timm\n",
    "from timm.models.efficientnet import *\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd977e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocropmin(image, threshold=100, kernsel_size = 10):\n",
    "        \n",
    "    img = image.copy()\n",
    "    \n",
    "    SIZE = img.shape[0]\n",
    "    imgfilt = ndimage.minimum_filter(img, size=kernsel_size)\n",
    "    img_b=np.where(imgfilt<threshold,0,255)\n",
    "    a=img_b[:,:,0].sum(axis=1)\n",
    "    a=np.concatenate(([0],a,[0]))\n",
    "\n",
    "    a_=np.where(a==0)[0]\n",
    "    mina=a_[np.argmax(a_[1:]-a_[:-1])]\n",
    "    maxa=a_[np.argmax(a_[1:]-a_[:-1])+1]-1\n",
    "\n",
    "    b=img_b[:,:,0].sum(axis=0)\n",
    "    b=np.concatenate(([0],b,[0]))\n",
    "\n",
    "    b_=np.where(b==0)[0]\n",
    "    minb=b_[np.argmax(b_[1:]-b_[:-1])]\n",
    "    maxb=b_[np.argmax(b_[1:]-b_[:-1])+1]-1\n",
    "\n",
    "    if  mina!=maxa and minb!=maxb:\n",
    "        imageout=img[mina:maxa,minb:maxb,:]\n",
    "    else:\n",
    "        imageout=img\n",
    "\n",
    "    return imageout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38758ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f00e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6d56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_list=[list(glob.glob(os.path.join(\"/home/fate/covid19_CT/input/train/covid\", \"*\"))),\n",
    "                list(glob.glob(os.path.join(\"/home/fate/covid19_CT/input/train/non_covid\", \"*\"))),\n",
    "                list(glob.glob(os.path.join(\"/home/fate/covid19_CT/input/valid/covid\", \"*\"))),\n",
    "                list(glob.glob(os.path.join(\"/home/fate/covid19_CT/input/valid/non_covid\", \"*\"))),\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93fe6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_list[1].remove(\"/home/fate/covid19_CT/input/train/non_covid/ct_scan1073\")\n",
    "all_train_list[1].remove(\"/home/fate/covid19_CT/input/train/non_covid/ct_scan_781\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c893391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2dd88ff543bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mstr1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_list in all_train_list:\n",
    "    diff_shape_ct_list=[]\n",
    "    \n",
    "    for i in tqdm(range(len(train_list))):\n",
    "        tmp_list=list(glob.glob(os.path.join(train_list[i], \"*\")))\n",
    "        tmp_shape_set=set()\n",
    "        for j in range(len(tmp_list)):\n",
    "\n",
    "            str1=tmp_list[j]\n",
    "            img=cv2.imread(str1)\n",
    "\n",
    "            try:\n",
    "                tmp_shape_set.add(img.shape)\n",
    "            except:\n",
    "                print(\"bug file\")\n",
    "                continue\n",
    "\n",
    "            img=autocropmin(img)\n",
    "\n",
    "            \n",
    "            str1=str1.replace(\"/valid/\",\"/valid_pure_crop/\")\n",
    "            str1=str1.replace(\"/train/\",\"/train_pure_crop/\")\n",
    "\n",
    "\n",
    "            folder_path=\"/\".join(str1.split(\"/\")[:-1])\n",
    "\n",
    "            if len(tmp_shape_set)!=1:\n",
    "                shutil.rmtree(folder_path)\n",
    "                diff_shape_ct_list.append(folder_path)\n",
    "                \n",
    "                break\n",
    "\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            cv2.imwrite(str1,img)\n",
    "       \n",
    "    for ct_path in diff_shape_ct_list:\n",
    "        \n",
    "        str2=ct_path\n",
    "        \n",
    "        str1=str2.replace(\"/valid_pure_crop/\",\"/valid/\")\n",
    "        str1=str1.replace(\"/train_pure_crop/\",\"/train/\")\n",
    "\n",
    "        tmp_list=list(glob.glob(os.path.join(str1, \"*\")))\n",
    "        last_file=str(len(tmp_list)-1)+\".jpg\"\n",
    "        str1=str1+\"/\"+last_file\n",
    "        str2=str2+\"/\"+last_file\n",
    "        img=cv2.imread(str1)\n",
    "        img=autocropmin(img)\n",
    "        folder_path=\"/\".join(str2.split(\"/\")[:-1])\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        cv2.imwrite(str2,img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433bee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bb1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
